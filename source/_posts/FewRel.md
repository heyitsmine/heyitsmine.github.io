---
title: FewRel简单笔记
date: 2019-12-14 17:06:11
categories:
- deep learning
tags:
- relation classification
- few-shot learning
---

# 摘要

FewRel是一个小样本关系分类数据集，该数据集由Wikipedia上的100种关系中的70000个句子组成，并由人工进行标注。<!--more--> 每个句子的关系首先通过远程离监督方法来识别，然后由人工修正。 我们将最新的SOTA小样本学习方法用于关系分类，并对这些方法进行全面评估。 实证结果表明，即使是最有效的小样本学习模型也难以完成这项任务，尤其是与人类的表现仍存在差距。 文章还指出，解决改任务需要多种不同的推理能力。 少打关系分类仍然是一个复杂的问题，仍需进一步研究，文章的详细分析了当前结果，并为未来的研究指明了多个方向。 有关数据集和基线的所有详细信息和资源均在http://zhuhao.me/fewrel 上发布。

关系分类（RC）是NLP中的一项重要任务，旨在确定给定句子中两个实体之间的正确关系。为完成该任务目前已有很多相关工作，包括核方法（Zelenko等，2002； Mooney和Bunescu，2006），嵌入方法（Gormley等，2015）和神经网络方法（Zeng等，2014）。这些常规模型的性能在很大程度上取决于费时且费力的已标注数据，这使其泛化能力受到限制。采用远程监督是缓解RC的主要方法（Mintz等人; Riedel等人; Hoffmann等人，2011; Surdeanu等人，2012; Zeng等人，2015; Lin等人， 2016），远程监督通过启发式对齐知识库（KB）和文本以自动注释足够数量的训练样本。我们使用基准数据集NYT-10评估了Lin等人提出的模型（2016），该工作是随后是最新的技术水平（Zeng等，2017; Ji等，2017; Huang和Wang，2017; Wu等，2017; Liu等，2017）的基础。尽管在常见的关系上取得了不错的结果，但是当关系的训练样本数量减少时，分类准确率急剧下降。 NYT-10中大约58％的关系是长尾关系，少于100个实例。此外，远距离监督存在标注错误的问题，这使得对长尾关系进行分类变得更加困难。因此，有必要研究如何在小样本条件下训练RC模型。

早期的方法使用**迁移学习**，模型先在类别常见且样本充足的数据集上训练，然后在只有少量样本的不常见类别数据上微调。

**尺度学习方法**学习类别之间的距离分布。

**元学习**支持模型从之前的经验中学习“快速学习”并快速归纳出新概念的能力。

